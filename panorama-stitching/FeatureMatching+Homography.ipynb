{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operational Time= 1010.141134262085  ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "start = time.time()\n",
    "img1 = cv2.imread('../images/left1.png', 0)  # queryImage\n",
    "img2 = cv2.imread('../images/right1.png', 0)  # trainImage\n",
    "img1 = imutils.resize(img1, width=800)\n",
    "img2 = imutils.resize(img2, width=800)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 2\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "    h, w = img1.shape\n",
    "    pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "    img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good), MIN_MATCH_COUNT))\n",
    "    matchesMask = None\n",
    "\n",
    "draw_params = dict(matchColor=(0, 255, 0),  # draw matches in green color\n",
    "                   singlePointColor=None,\n",
    "                   matchesMask=matchesMask,  # draw only inliers\n",
    "                   flags=2)\n",
    "\n",
    "img3 = cv2.drawMatches(img1, kp1, img2, kp2, good, None, **draw_params)\n",
    "print(\"Operational Time=\",(time.time()-start)*1000,\" ms\") # Time in milli sec\n",
    "cv2.imshow(\"image\",img3)\n",
    "#plt.imshow(img3)\n",
    "if cv2.waitKey(0):\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operational Time= 890.1157379150391  ms\n"
     ]
    }
   ],
   "source": [
    "# Python 4.3.0\n",
    "# BF technique\n",
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "start = time.time()\n",
    "img1 = cv2.imread('../images/left1.png', 0)  # queryImage\n",
    "img2 = cv2.imread('../images/right1.png', 0)  # trainImage\n",
    "img1 = imutils.resize(img1, width=800)\n",
    "img2 = imutils.resize(img2, width=800)\n",
    "if img1 is None or img2 is None:\n",
    "    print('Could not open or find the images!')\n",
    "    exit(0)\n",
    "#-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n",
    "minHessian = 400\n",
    "detector = cv2.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "keypoints1, descriptors1 = detector.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = detector.detectAndCompute(img2, None)\n",
    "#-- Step 2: Matching descriptor vectors with a brute force matcher\n",
    "# Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_BRUTEFORCE)\n",
    "matches = matcher.match(descriptors1, descriptors2)\n",
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, img_matches)\n",
    "#-- Show detected matches\n",
    "print(\"Operational Time=\",(time.time()-start)*1000,\" ms\") # Time in milli sec\n",
    "cv2.imshow('Matches', img_matches)\n",
    "if cv2.waitKey(0):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"image\",img2[:,:int((img2.shape[1])*0.45)])\n",
    "if cv2.waitKey(0):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((img1.shape[1])*0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operational Time= 826.1146545410156  ms\n"
     ]
    }
   ],
   "source": [
    "# FLANN Based\n",
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "start = time.time()\n",
    "img1 = cv2.imread('../images/left1.png', 0)  # queryImage\n",
    "img2 = cv2.imread('../images/right1.png', 0)  # trainImage\n",
    "img1 = imutils.resize(img1, width=800)\n",
    "img2 = imutils.resize(img2, width=800)\n",
    "\n",
    "if img1 is None or img2 is None:\n",
    "    print('Could not open or find the images!')\n",
    "    exit(0)\n",
    "\n",
    "#-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n",
    "minHessian = 400\n",
    "detector = cv2.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "keypoints1, descriptors1 = detector.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "#-- Step 2: Matching descriptor vectors with a FLANN based matcher\n",
    "# Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "knn_matches = matcher.knnMatch(descriptors1, descriptors2, 2)\n",
    "\n",
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.7\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "print(\"Operational Time=\",(time.time()-start)*1000,\" ms\") # Time in milli sec\n",
    "#-- Show detected matches\n",
    "cv2.imshow('Good Matches', img_matches)\n",
    "\n",
    "if cv2.waitKey(0):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
